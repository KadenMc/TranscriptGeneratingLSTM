model:
    # Hyperparameters
    lstm_nodes: 448
    dropout: 0.15
    recurrent_dropout: 0
    max_length: 100

train:
    # Paths
    text_file: data/data.txt
    Xy_file: data/Xy.npz
    model_file: models/model.h5

    # Hyperparameters
    epochs: 70
    batch_size: 512
    
    initial_lr: 0.01
    minimum_lr: 0.001
    decay_lr: 0.001
    
    validation_split: 0.15

    # Training callbacks
    epoch_end_callback: True
    checkpoint_callback: True
    early_stopping_callback: True
    early_stopping_patience: 3

    # Specify whether training on GPU(s)
    GPU: True

demo:
    # Temperature, or diversity
    temperature: 0.5
    
    # Demo length in characters
    length: 300